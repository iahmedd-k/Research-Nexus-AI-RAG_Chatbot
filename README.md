ğŸ“š Research-Nexus AI

Research-Nexus is an AI-powered research assistant that allows users to upload documents (PDFs), extract knowledge, and ask intelligent questions using a Retrieval-Augmented Generation (RAG) pipeline.

Built with Next.js App Router, Supabase, Pinecone, and Gemini AI, this project demonstrates a production-grade AI document analysis system with a modern dashboard UI.

ğŸš€ Features

ğŸ” Authentication (Supabase Auth)

ğŸ“„ Upload research papers (PDF)

ğŸ§  Text extraction & intelligent chunking

ğŸ” Vector search with Pinecone

ğŸ’¬ Ask questions across uploaded documents

âš¡ RAG-based answer generation

ğŸ§ª Mock embeddings for development (quota-safe)

ğŸ“± Fully responsive dashboard UI

ğŸ§© Pluggable AI providers (Gemini / OpenAI ready)

ğŸ§  Architecture Overview
User Uploads PDF
        â†“
Supabase Storage (File)
        â†“
PDF Text Extraction (Server)
        â†“
Text Chunking
        â†“
Embedding Generation
   (Mock / Gemini)
        â†“
Pinecone Vector DB
        â†“
Semantic Search
        â†“
AI Answer Generation

ğŸ›  Tech Stack
Frontend

Next.js 16 (App Router)

TypeScript

Tailwind CSS

Lucide Icons

Backend

Next.js API Routes

Supabase (Auth + Storage)

Pinecone (Vector Database)

AI / ML

Google Gemini API (Chat & Embeddings)

Mock Embeddings (Dev Mode)

RAG (Retrieval-Augmented Generation)

ğŸ“‚ Project Structure
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â””â”€â”€ signup/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â””â”€â”€ layout.tsx
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts
â”‚   â””â”€â”€ page.tsx
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ supabase-client.ts
â”‚   â”œâ”€â”€ pinecone.ts
â”‚   â””â”€â”€ embeddings.ts
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ pdfparser.ts
â”‚   â””â”€â”€ chunker.ts
â”‚
â””â”€â”€ styles/

ğŸ§ª Mock Embeddings (Development Mode)

To avoid API quota issues during development, the project uses deterministic mock embeddings:

if (process.env.NODE_ENV === 'development') {
  return createMockEmbedding(text);
}

Why?

Enables full RAG pipeline testing

Faster iteration

Zero API cost

Easy switch to production embeddings

ğŸ” Switching to Real Embeddings

Update environment variables:

NODE_ENV=production
GEMINI_API_KEY=your_key_here


No code changes required.

ğŸ” Environment Variables

Create a .env.local file:

NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

PINECONE_API_KEY=
PINECONE_INDEX_NAME=

GEMINI_API_KEY=

â–¶ï¸ Getting Started
# Install dependencies
npm install

# Run development server
npm run dev


Open:
ğŸ‘‰ http://localhost:3000

ğŸ§  RAG vs LangChain

This project uses custom RAG logic instead of LangChain.

Why?

Full control over data flow

Better debugging

Lower overhead

Cleaner architecture for Next.js

LangChain can be added later if needed.

ğŸ¯ Use Cases

Academic research assistant

Internal document QA

Knowledge base chatbots

AI SaaS MVP

Client demos / portfolios

ğŸ“¸ Screenshots
